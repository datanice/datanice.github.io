<!DOCTYPE html>
<html lang="en">

<head>
  <!-- ## for client-side less
  <link rel="stylesheet/less" type="text/css" href="/theme/css/style.less">
  <script src="http://cdnjs.cloudflare.com/ajax/libs/less.js/1.7.3/less.min.js" type="text/javascript"></script>
  -->

  <link rel="stylesheet" type="text/css" href="/theme/css/style.css">
  <link rel="stylesheet" type="text/css" href="/theme/css/pygments.css">
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=PT+Sans|PT+Serif|PT+Mono">
  <link type="text/css" href="/theme/css/ui-slider.css" rel="stylesheet" />
  <link type="text/css" href="/theme/css/bootstrap.css" rel="stylesheet" />
  <link type="text/css" href="/theme/css/viz.css" rel="stylesheet" />

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="author" content="Datanice">
  <meta name="description" content="Posts and writings by Datanice">


<meta name="keywords" content="">

  <title>
    Datanice
&ndash; Sentiment analysis for Youtube channels - with NLTK  </title>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-79232568-1', 'auto');
  ga('send', 'pageview');

</script>
</head>

<body>
  <aside>
    <div id="user_meta">
      <a href="">
        <img src="https://datanice.github.io//images/datanice_logo.png" alt="logo">
      </a>
      <div class = "align-title">
        <h2 class="site-title"><a  href="/">Datanice</a></h2>
        <p>Exploring the world with data</p>
      </div>
      <ul class="base-links">
        <li><a href="https://twitter.com/datanice_" target="_blank">Twitter</a></li>
      </ul>
    </div>
  </aside>

  <main>
    <header>
      <p>
      <a href="/">Index</a> &brvbar; <a href="/archives.html">Archives</a>
      </p>
    </header>

<article>
  <div class="article_title entry-title">
    <h3><a href="/sentiment-analysis-for-youtube-channels-with-nltk.html">Sentiment analysis for Youtube channels - with NLTK</a></h3>
  </div>
  <div class="article_text">
    <p>In this tutorial, we 'll first take a look at the Youtube API to
retrieve comments data about the channel as well as basic information
about the likes count and view count of the videos. Then, we will use
Nltk to see most frequently used words in the comments and plot some
sentiment graphs.</p>
<p><a href="https://datanice.files.wordpress.com/2015/09/download1-e1441826980693.jpeg"><img alt="download" src="https://datanice.files.wordpress.com/2015/09/download1-e1441826980693.jpeg" /></a><br />
<!--more--></p>
<h1>The Data</h1>
<p>With the script below, we first query the video channels providing the
channel ID then for every video we get a list of comments (Youtube
limits this number to 20 comments per query)</p>
<div class="highlight"><pre><span></span>from apiclient.discovery import build 
import pandas as pd 
import time

DEVELOPER_KEY = &quot;&quot; 
YOUTUBE_API_SERVICE_NAME = &quot;&quot;
YOUTUBE_API_VERSION = &quot;&quot;

youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=DEVELOPER_KEY)

def get_videos_FromChanel(youtube, channelId,order):
    search_response = youtube.search().list(
        channelId=channelId,
        type=&quot;video&quot;,
        part=&quot;id,snippet&quot;,
        maxResults=50,
        order=order
    ).execute()

    return search_response.get(&quot;items&quot;, [])

def get_comment_threads(youtube, videos):
    tempComments = []
    for video in videos:
        time.sleep(1.0)
        print video[&quot;snippet&quot;][&quot;title&quot;]
        results = youtube.commentThreads().list(
            part=&quot;snippet&quot;,
            videoId=video[&quot;id&quot;][&quot;videoId&quot;],
            textFormat=&quot;plainText&quot;,
            maxResults=20,
            order=&#39;relevance&#39;
        ).execute()


        for item in results[&quot;items&quot;]:
            comment = item[&quot;snippet&quot;][&quot;topLevelComment&quot;]
            tempComment = dict(videoId=video[&quot;id&quot;][&quot;videoId&quot;], videoName=video[&quot;snippet&quot;][&quot;title&quot;],nbrReplies = item[&quot;snippet&quot;][&quot;totalReplyCount&quot;],author = comment[&quot;snippet&quot;][&quot;authorDisplayName&quot;],likes = comment[&quot;snippet&quot;][&quot;likeCount&quot;],publishedAt=comment[&quot;snippet&quot;][&quot;publishedAt&quot;],text = comment[&quot;snippet&quot;][&quot;textDisplay&quot;].encode(&#39;utf-8&#39;).strip())
            tempComments.append(tempComment)

    return tempComments
</pre></div>


<p>then you can call the function using :</p>
<div class="highlight"><pre><span></span>videos = get_videos_FromChanel(youtube, &quot;CHANNEL_ID&quot;,&quot;viewCount&quot;)
</pre></div>


<h1>Statistics</h1>
<p>Youtube has a special option to retreive the statistic data, we just
have to query the video list method using the "statistic" option.</p>
<div class="highlight"><pre><span></span>def getVideoInfos(videos):
    videoList = {}
    for search_result in videos:
         if search_result[&quot;id&quot;][&quot;kind&quot;] == &quot;youtube#video&quot;:
             videoList[search_result[&quot;id&quot;][&quot;videoId&quot;]] = search_result[&quot;snippet&quot;][&quot;title&quot;]

    s = &#39;,&#39;.join(videoList.keys())
    videos_list_response = youtube.videos().list(id=s,part=&#39;id,statistics&#39;).execute()
    res = []
    for i in videos_list_response[&#39;items&#39;]:
         temp_res = dict(v_title = videoList[i[&#39;id&#39;]])
         temp_res.update(i[&#39;statistics&#39;])
         res.append(temp_res)

    data = pd.DataFrame.from_dict(res)
    data[&#39;viewCount&#39;] = data[&#39;viewCount&#39;].map(lambda x : float(x))
    data[&#39;commentCount&#39;] = data[&#39;commentCount&#39;].map(lambda x : float(x))
    return data

data = getVideoInfos(videos)

infos.sort(&#39;viewCount&#39;,ascending=0).head(20).plot(kind=&#39;bar&#39;, x=&#39;v_title&#39;,y=&#39;viewCount&#39;)
</pre></div>


<p>This is what I get for the view count of the <a href="https://www.youtube.com/channel/UClYb9NpXnRemxYoWbcYANsA">shots of
Awe</a> videos
channel:<br />
<a href="https://datanice.files.wordpress.com/2015/09/screenshot-from-2015-09-09-175623.png"><img alt="Screenshot from 2015-09-09
17:56:23" src="https://datanice.files.wordpress.com/2015/09/screenshot-from-2015-09-09-175623.png" /></a></p>
<p>We can have the same plots for likes counts and comments count, and plot
scatter plots to see if there is a correlation between these features.</p>
<p>We can note that the third video has only been uploaded for a few days
at the time I’m writing this article, that's what we call a buzz video.</p>
<p>An interesting chart to plot would be the number of views/time online.</p>
<h1>Comments analysis</h1>
<ul>
<li>
<h3>Word Frequency</h3>
</li>
</ul>
<p>What do people talk about in the comments ? What do they like/hate the
most about the channel ?<br />
In order to answer these questions we can look at the word frequency in
the comments. We can use the "nltk" package to see the distribution :</p>
<div class="highlight"><pre><span></span>import nltk
from nltk.probability import *
from nltk.corpus import stopwords
import pandas as pd

all = pd.read_json(&quot;comments.csv&quot;)

stop_eng = stopwords.words(&#39;english&#39;)
customstopwords =[]

tokens = []
sentences = []
tokenizedSentences =[]
for txt in all.text:
    sentences.append(txt.lower())
    tokenized = [t.lower().encode(&#39;utf-8&#39;).strip(&quot;:,.!?&quot;) for t in txt.split()]
    tokens.extend(tokenized)
    tokenizedSentences.append(tokenized)

hashtags = [w for w in tokens if w.startswith(&#39;#&#39;)]
ghashtags = [w for w in tokens if w.startswith(&#39;+&#39;)]
mentions = [w for w in tokens if w.startswith(&#39;@&#39;)]
links = [w for w in tokens if w.startswith(&#39;http&#39;) or w.startswith(&#39;www&#39;)]
filtered_tokens = [w for w in tokens if not w in stop_eng and not w in customstopwords and w.isalpha() and not len(w)&lt;3 and not w in hashtags and not w in ghashtags and not w in links and not w in mentions]

fd = FreqDist(filtered_tokens)
</pre></div>


<p>FreqDist returns a list of tuples containing each word and the number of
its occurences. Let"s plot a bar chart to visualize it:</p>
<div class="highlight"><pre><span></span>import scipy
import pylab
import operator
from operator import itemgetter, attrgetter

sortedTuples = sorted(fd.items(), key=operator.itemgetter(1), reverse=True)
a = [i[0] for i in sorted_x[0:20]]
b = [i[1] for i in sorted_x[0:20]]

x = scipy.arange(len(b))
y = scipy.array(b)
f = pylab.figure()
ax = f.add_axes([0.5, 0.5, 1.5, 1.5])
ax.bar(x, y, align=&#39;center&#39;)
ax.set_xticks(x)
ax.set_xticklabels(a)
f.show()
</pre></div>


<p>And the result :</p>
<p><a href="https://datanice.files.wordpress.com/2015/09/screenshot-from-2015-09-09-203414.png"><img alt="Screenshot from 2015-09-09
20:34:14" src="https://datanice.files.wordpress.com/2015/09/screenshot-from-2015-09-09-203414.png" /></a></p>
<p>The most used words are "love" (141 occurrences), "like" (89
occurrences) then "think" and "life". Pretty deep !</p>
<ul>
<li>
<h3>Sentiment Analysis</h3>
</li>
</ul>
<p>In order to analyze the comments sentiments, we are going to train a
Naive Bayes Classifier using a dataset provided by nltk. This could be
imroved using a better training dataset for comments or tweets.</p>
<p>The reviews are classified as "negative" or "positive", and our
classifier will return the probability of each label. We will compute a
score = prob("positive") - prob("negative") to get a score between -1 an
1.</p>
<h4>Training the classifier</h4>
<div class="highlight"><pre><span></span>import pandas as pd
import nltk.classify.util
from nltk.classify import NaiveBayesClassifier
from nltk.corpus import movie_reviews

###############
def word_feats(words):
    return dict([(word, True) for word in words])
###############

negids = movie_reviews.fileids(&#39;neg&#39;)
posids = movie_reviews.fileids(&#39;pos&#39;)
 
negfeats = [(word_feats(movie_reviews.words(fileids=[f])), &#39;neg&#39;) for f in negids]
posfeats = [(word_feats(movie_reviews.words(fileids=[f])), &#39;pos&#39;) for f in posids]

trainfeats = negfeats + posfeats
 
classifier = NaiveBayesClassifier.train(trainfeats)
###############

all = pd.read_json(&quot;comments.csv&quot;)

all[&#39;tokenized&#39;] = all[&#39;text&#39;].apply(lambda x: [t.lower().encode(&#39;utf-8&#39;).strip(&quot;:,.!?&quot;) for t in x.split()] )
all[&#39;sentiment&#39;] = all[&#39;tokenized&#39;].apply(lambda x: classifier.prob_classify(word_feats(x)).prob(&#39;pos&#39;) - classifier.prob_classify(word_feats(x)).prob(&#39;neg&#39;) )
</pre></div>


<p>Once the classifier trained, we added a column with the sentiment score
using the "classifier.prob_classify" function.</p>
<p>Let's see the results for the first video in a scatter plot (versus
likes)</p>
<div class="highlight"><pre><span></span>videos = all.videoId.unique()
all[all.videoId==videos[1]].plot(kind=&#39;scatter&#39;, x=&#39;sentiment&#39;, y=&#39;likes&#39;, figsize=(12,8))
</pre></div>


<p><a href="https://datanice.files.wordpress.com/2015/09/screenshot-from-2015-09-09-210331.png"><img alt="Screenshot from 2015-09-09
21:03:31" src="https://datanice.files.wordpress.com/2015/09/screenshot-from-2015-09-09-210331.png" /></a></p>
<p>For the next one,</p>
<p><a href="https://datanice.files.wordpress.com/2015/09/screenshot-from-2015-09-09-210427.png"><img alt="Screenshot from 2015-09-09
21:04:27" src="https://datanice.files.wordpress.com/2015/09/screenshot-from-2015-09-09-210427.png" /></a></p>
<p>A cool thing to do here is to see what's the text of every comment. The
best thing to do is to have an interactive plot where hovering on a
point shows the comment text. This could be done with the
<a href="http://d3js.org/">d3.js</a> library. We can also make the axis interactive
and add animations to animate the points when for example changing the
sentiment axis to the publishing date of the comment...</p>
<p>Next Steps:</p>
<ul>
<li>Adding a plot for "number of views"/"time online"</li>
<li>Interactive d3.js plot to see the comment text when hovering on he
    comment.</li>
</ul>
  </div>
  <div class="article_meta">
    <a href="https://twitter.com/share" class="twitter-share-button" data-via="datanice_">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
    
    <p>Posted on: Wed 09 September 2015</p>
    <p>
      <!-- Category: <a href="/category/non-classe.html">Non classé</a> -->
    </p>
  </div>

  <div id="article_comments">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_identifier = "sentiment-analysis-for-youtube-channels-with-nltk.html";
        (function() {
             var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
             dsq.src = '//datanice.disqus.com/embed.js';
             (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
         })();
    </script>
  </div>

</article>


    <div id="ending_message">
      <p>&copy; Datanice. Built using <a href="http://getpelican.com" target="_blank">Pelican</a>. Theme by Giulio Fidente on <a href="https://github.com/gfidente/pelican-svbhack" target="_blank">github</a>. </p>
    </div>
  </main>
</body>
</html>